{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b408d82-9aa5-4fee-aae1-94c7e6997e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script saved as explainable_AI_app.py\n",
      "Theme configuration saved to .streamlit/config.toml\n"
     ]
    }
   ],
   "source": [
    "# Save script to a Python file\n",
    "script_content = \"\"\"\n",
    "# Importing required libraries\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Preset dataset path\n",
    "PRESET_DATASET_PATH = \"C:/Users/HP/Downloads/Combined_XAIC_Dimensions.csv\"\n",
    "\n",
    "# Function to add missing columns based on existing dataset attributes dynamically\n",
    "def map_dimensions(dataset):\n",
    "    if 'Ability to Abstract' not in dataset.columns:\n",
    "        dataset['Ability to Abstract'] = dataset['Data Type'].apply(\n",
    "            lambda x: 'High' if x in ['Image', 'Audio'] else 'Medium' if x in ['Text', 'Alphanumeric'] else 'Low'\n",
    "        )\n",
    "    if 'Data Type Understanding' not in dataset.columns:\n",
    "        dataset['Data Type Understanding'] = dataset['Data Type'].apply(\n",
    "            lambda x: 'High' if x in ['Image', 'Video'] else 'Medium' if x == 'Audio' else 'Low'\n",
    "        )\n",
    "    if 'Algorithm Function' not in dataset.columns:\n",
    "        dataset['Algorithm Function'] = dataset['Algorithms'].apply(\n",
    "            lambda x: 'Predictive' if 'Regression' in x or 'Neural Network' in x else\n",
    "                      'Descriptive' if 'Clustering' in x else 'Prescriptive'\n",
    "        )\n",
    "    if 'Human Interaction Type' not in dataset.columns:\n",
    "        dataset['Human Interaction Type'] = dataset['Algorithm Function'].apply(\n",
    "            lambda x: 'Direct' if x == 'Prescriptive' else\n",
    "                      'Indirect' if x == 'Predictive' else 'Automatic'\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "# Function to recommend the most suitable Explainable AI (XAI) tool\n",
    "def recommend_xai_tool(ability_to_abstract, data_type_understanding, algorithm_function, human_interaction, best_model):\n",
    "    st.write(\"### üî¨ Recommended XAI Tool for Explainable AI\")\n",
    "    if data_type_understanding == 'Medium' or algorithm_function in ['Descriptive', 'Predictive']:\n",
    "        return \"LIME\", \"LIME is recommended as it works effectively with descriptive or predictive models, providing localized explanations for the data.\"\n",
    "\n",
    "    if ability_to_abstract == 'High' and data_type_understanding == 'High' and best_model == \"Random Forest\":\n",
    "        return \"DeepLIFT\", \"DeepLIFT is recommended for models with complex data like images or audio, offering insights into neuron activations in neural networks.\"\n",
    "\n",
    "    if ability_to_abstract == 'High' and data_type_understanding == 'High':\n",
    "        return \"SHAP (Shapley Values)\", \"SHAP is recommended as it provides detailed feature importance and model explanation, ideal for high abstraction and complex models.\"\n",
    "\n",
    "    if ability_to_abstract == 'High' and algorithm_function in ['Predictive', 'Descriptive'] and best_model == \"Random Forest\":\n",
    "        return \"Activation Atlases\", \"Activation Atlases are ideal for vision-based tasks, providing a visualization of feature activations.\"\n",
    "\n",
    "    if human_interaction == 'Direct' and algorithm_function == 'Prescriptive':\n",
    "        return \"RuleX\", \"RuleX is recommended for prescriptive models and direct human interactions, providing rule-based explanations for decision-making.\"\n",
    "\n",
    "    return \"SHAP (Shapley Values)\", \"SHAP is versatile and can be used for various data types and algorithms, making it a reliable choice.\"\n",
    "\n",
    "# Function to display a preview of the selected dimensions\n",
    "def preview_selected_dimensions(ability_to_abstract, data_type_understanding, algorithm_function, human_interaction):\n",
    "    st.write(\"### üõ†Ô∏è Selected Dimensions Summary\")\n",
    "    summary_data = pd.DataFrame({\n",
    "        'Dimension': ['Ability to Abstract', 'Data Type Understanding', 'Algorithm Function', 'Human Interaction Type'],\n",
    "        'Value': [ability_to_abstract, data_type_understanding, algorithm_function, human_interaction]\n",
    "    })\n",
    "    st.dataframe(summary_data)\n",
    "\n",
    "# Visualization to compare XAI tools based on their features\n",
    "def visualize_xai_comparison(best_tool):\n",
    "    st.write(\"### üõ†Ô∏è Why this XAI tool is recommended?\")\n",
    "    \n",
    "    # Criteria and scores for various XAI tools (example scores)\n",
    "    criteria = [\"Interpretability\", \"Scalability\", \"Usability\", \"Compatibility\"]\n",
    "    tools_scores = {\n",
    "        \"LIME\": [4, 3, 5, 4],\n",
    "        \"SHAP (Shapley Values)\": [5, 4, 4, 5],\n",
    "        \"DeepLIFT\": [4, 3, 3, 5],\n",
    "        \"Activation Atlases\": [3, 2, 4, 5],\n",
    "        \"RuleX\": [5, 4, 3, 4],\n",
    "    }\n",
    "    \n",
    "    # Prepare radar chart data\n",
    "    fig = go.Figure()\n",
    "    for tool, scores in tools_scores.items():\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=scores,\n",
    "            theta=criteria,\n",
    "            fill='toself' if tool == best_tool else 'none',\n",
    "            name=tool,\n",
    "            line=dict(dash='solid' if tool == best_tool else 'dash'),\n",
    "            opacity=1.0 if tool == best_tool else 0.5\n",
    "        ))\n",
    "\n",
    "    # Update layout for better clarity\n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                visible=True,\n",
    "                range=[0, 5],\n",
    "                tickvals=[0, 1, 2, 3, 4, 5],\n",
    "                ticktext=[\"Poor\", \"Below Avg\", \"Average\", \"Good\", \"Excellent\"]\n",
    "            )\n",
    "        ),\n",
    "        title=f\"Comparison of {best_tool} with Other XAI Tools\",\n",
    "        legend_title=\"XAI Tools\",\n",
    "        height=600,\n",
    "        width=800\n",
    "    )\n",
    "    st.plotly_chart(fig)\n",
    "# Function to create visualization for the 4 dimensions mapped to knowledge and explanation\n",
    "def visualize_dimensions_mapped_to_knowledge_and_explanation(ability_to_abstract, data_type_understanding, algorithm_function, human_interaction):\n",
    "    st.write(\"### üìä Visualization of Dimensions: Knowledge and Explanation Levels\")\n",
    "\n",
    "    # Constructing a DataFrame for visualization\n",
    "    data = pd.DataFrame({\n",
    "        'Dimension': ['Ability to Abstract', 'Data Type Understanding', 'Algorithm Function', 'Human Interaction Type'],\n",
    "        'Knowledge': [\n",
    "            5 if ability_to_abstract == 'High' else 3 if ability_to_abstract == 'Medium' else 1,\n",
    "            5 if data_type_understanding == 'High' else 3 if data_type_understanding == 'Medium' else 1,\n",
    "            5 if algorithm_function in ['Predictive', 'Prescriptive'] else 3 if algorithm_function == 'Descriptive' else 1,\n",
    "            5 if human_interaction == 'Direct' else 3 if human_interaction == 'Indirect' else 1\n",
    "        ],\n",
    "        'Explanation': [\n",
    "            5 if ability_to_abstract == 'High' else 3 if ability_to_abstract == 'Medium' else 1,\n",
    "            5 if data_type_understanding == 'High' else 3 if data_type_understanding == 'Medium' else 1,\n",
    "            5 if algorithm_function in ['Predictive', 'Prescriptive'] else 3 if algorithm_function == 'Descriptive' else 1,\n",
    "            5 if human_interaction == 'Direct' else 3 if human_interaction == 'Indirect' else 1\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Create grouped bar chart with Plotly\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add bars for Knowledge\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data['Dimension'],\n",
    "        y=data['Knowledge'],\n",
    "        name='Knowledge Level',\n",
    "        marker_color='blue',\n",
    "        hovertemplate='<b>Dimension:</b> %{x}<br>' +\n",
    "                      '<b>Knowledge Level:</b> %{y}<br>' +\n",
    "                      '<extra></extra>'\n",
    "    ))\n",
    "\n",
    "    # Add bars for Explanation\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data['Dimension'],\n",
    "        y=data['Explanation'],\n",
    "        name='Explanation Level',\n",
    "        marker_color='orange',\n",
    "        hovertemplate='<b>Dimension:</b> %{x}<br>' +\n",
    "                      '<b>Explanation Level:</b> %{y}<br>' +\n",
    "                      '<extra></extra>'\n",
    "    ))\n",
    "\n",
    "    # Adjust chart layout\n",
    "    fig.update_layout(\n",
    "        title=\"Knowledge and Explanation Levels for Selected Dimensions\",\n",
    "        xaxis=dict(title=\"Dimensions\"),\n",
    "        yaxis=dict(\n",
    "            title=\"Scaled Level (0 to 5)\",\n",
    "            tickvals=[0, 1, 2, 3, 4, 5],\n",
    "            ticktext=[\"Low\", \"Below Avg\", \"Medium\", \"Good\", \"High\"]\n",
    "        ),\n",
    "        barmode='group',\n",
    "        legend=dict(title=\"Levels\"),\n",
    "        height=500,\n",
    "        width=800\n",
    "    )\n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "    # Function to visualize why Random Forest is a strong candidate for Explainable AI\n",
    "def visualize_rf_xai_strength():\n",
    "    st.write(\"### üåü Random Forest a strong choice for Explainable AI\")\n",
    "    \n",
    "    # Criteria for model comparison\n",
    "    criteria = [\"Feature Interpretability\", \"Model Complexity\", \"Performance\", \"Global vs. Local Explanations\"]\n",
    "    \n",
    "    # Scores for Random Forest and other common models\n",
    "    models_scores = {\n",
    "        \"Random Forest\": [5, 4, 5, 5],\n",
    "        \"Neural Networks\": [2, 1, 5, 3],\n",
    "        \"SVM\": [3, 3, 4, 3],\n",
    "        \"Linear Regression\": [5, 5, 3, 2],\n",
    "        \"KNN\": [3, 4, 4, 2]\n",
    "    }\n",
    "    \n",
    "    # Create radar chart with Plotly\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add data for each model\n",
    "    for model, scores in models_scores.items():\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=scores,\n",
    "            theta=criteria,\n",
    "            fill='toself' if model == \"Random Forest\" else 'none',\n",
    "            name=model,\n",
    "            line=dict(dash='solid' if model == \"Random Forest\" else 'dash'),\n",
    "            opacity=1.0 if model == \"Random Forest\" else 0.5\n",
    "        ))\n",
    "    \n",
    "    # Customize chart layout\n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                visible=True,\n",
    "                range=[0, 5],\n",
    "                tickvals=[0, 1, 2, 3, 4, 5],\n",
    "                ticktext=[\"Poor\", \"Below Avg\", \"Avg\", \"Good\", \"Excellent\"]\n",
    "            )\n",
    "        ),\n",
    "        title=\"Comparison of Random Forest with Other Models for Explainable AI\",\n",
    "        legend_title=\"Models\",\n",
    "        height=600,\n",
    "        width=800\n",
    "    )\n",
    "    \n",
    "    st.plotly_chart(fig)\n",
    "\n",
    "\n",
    "# Streamlit app begins here\n",
    "st.title(\"üîç Explainable AI\")\n",
    "st.write(\"üìÇ Using the preset dataset to begin.\")\n",
    "\n",
    "# Load the preset dataset\n",
    "try:\n",
    "    dataset = pd.read_csv(PRESET_DATASET_PATH)\n",
    "    st.write(\"Preset dataset loaded successfully! üéâ\")\n",
    "    st.write(\"üìã Preview of the preset dataset:\")\n",
    "    st.dataframe(dataset.head())\n",
    "except FileNotFoundError:\n",
    "    st.error(\"Preset dataset not found. Please ensure the file exists at the specified path.\")\n",
    "    dataset = None\n",
    "\n",
    "if dataset is not None:\n",
    "    dataset = map_dimensions(dataset)\n",
    "\n",
    "    # Selection inputs for filtering the dataset\n",
    "    occupations = dataset['Occupation'].unique()\n",
    "    selected_occupation = st.selectbox(\"üëî Choose an occupation\", occupations)\n",
    "    industries = dataset['Industry'].unique()\n",
    "    selected_industry = st.selectbox(\"üè¢ Choose an industry\", industries)\n",
    "    data_types = dataset['Data Type'].unique()\n",
    "    selected_data_type = st.selectbox(\"üóÇÔ∏è Choose a data type\", data_types)\n",
    "\n",
    "    if selected_occupation and selected_industry and selected_data_type:\n",
    "        filtered_data = dataset[(dataset['Occupation'] == selected_occupation) &\n",
    "                                (dataset['Industry'] == selected_industry) &\n",
    "                                (dataset['Data Type'] == selected_data_type)]\n",
    "\n",
    "        if not filtered_data.empty:\n",
    "            st.write(\"Filtered dataset preview:\")\n",
    "            st.dataframe(filtered_data.head())\n",
    "\n",
    "            # Extract modal values for visualization and modeling\n",
    "            ability_to_abstract = filtered_data['Ability to Abstract'].mode()[0]\n",
    "            data_type_understanding = filtered_data['Data Type Understanding'].mode()[0]\n",
    "            algorithm_function = filtered_data['Algorithm Function'].mode()[0]\n",
    "            human_interaction = filtered_data['Human Interaction Type'].mode()[0]\n",
    "\n",
    "            # Preview selected dimensions\n",
    "            st.write(\"### Selected Dimensions Summary\")\n",
    "            preview_data = pd.DataFrame({\n",
    "                'Dimension': ['Ability to Abstract', 'Data Type Understanding', 'Algorithm Function', 'Human Interaction Type'],\n",
    "                'Value': [ability_to_abstract, data_type_understanding, algorithm_function, human_interaction]\n",
    "            })\n",
    "            st.dataframe(preview_data)\n",
    "\n",
    "            # Visualize dimensions mapped to knowledge and explanation\n",
    "            visualize_dimensions_mapped_to_knowledge_and_explanation(\n",
    "                ability_to_abstract, data_type_understanding, algorithm_function, human_interaction\n",
    "            )\n",
    "\n",
    "            # Target column selection for ML modeling\n",
    "            target_column = st.selectbox(\"üéØ Select the Target Column for Prediction\", dataset.columns)\n",
    "            if target_column:\n",
    "                features = dataset.drop(columns=[target_column])\n",
    "                target = dataset[target_column]\n",
    "                le = LabelEncoder()\n",
    "                features = features.apply(lambda col: le.fit_transform(col) if col.dtype == 'object' else col)\n",
    "                target = le.fit_transform(target)\n",
    "\n",
    "                # Handle imbalanced datasets using SMOTE or RandomOverSampler\n",
    "                target_series = pd.Series(target)\n",
    "                minority_class_size = target_series.value_counts().min()\n",
    "\n",
    "                if minority_class_size < 5:\n",
    "                    st.warning(\"Minority class too small for SMOTE. Using RandomOverSampler instead.\")\n",
    "                    oversampler = RandomOverSampler(random_state=42)\n",
    "                    X_resampled, y_resampled = oversampler.fit_resample(features, target)\n",
    "                else:\n",
    "                    smote = SMOTE(random_state=42, k_neighbors=min(5, minority_class_size - 1))\n",
    "                    X_resampled, y_resampled = smote.fit_resample(features, target)\n",
    "\n",
    "                # Train/test split and Random Forest model training\n",
    "                X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "                X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "                rf_model = RandomForestClassifier(\n",
    "                    random_state=42, n_estimators=200, max_depth=10,\n",
    "                    min_samples_split=10, min_samples_leaf=5\n",
    "                )\n",
    "                rf_model.fit(X_train, y_train)\n",
    "                rf_val_pred = rf_model.predict(X_val)\n",
    "                rf_accuracy = accuracy_score(y_val, rf_val_pred)\n",
    "\n",
    "                st.write(f\"Random Forest Validation Accuracy: **{rf_accuracy:.2f}**\")\n",
    "                # After the Random Forest validation accuracy output\n",
    "                \n",
    "\n",
    "# Explain why Random Forest is the best for XAI\n",
    "                visualize_rf_xai_strength()\n",
    "\n",
    "\n",
    "                # Recommend the best XAI tool\n",
    "                best_xai_tool, xai_tool_explanation = recommend_xai_tool(\n",
    "                    ability_to_abstract,\n",
    "                    data_type_understanding,\n",
    "                    algorithm_function,\n",
    "                    human_interaction,\n",
    "                    \"Random Forest\"\n",
    "                )\n",
    "                st.write(f\"**{best_xai_tool}**\")\n",
    "                st.write(f\"Why? {xai_tool_explanation}\")\n",
    "\n",
    "                # Generate the radar chart for XAI comparison\n",
    "                visualize_xai_comparison(best_xai_tool)\n",
    "        else:\n",
    "            st.warning(\"No matching data found for the selected combination.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save the script to a file\n",
    "file_name = \"explainable_AI_app.py\"\n",
    "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(f\"Script saved as {file_name}\")\n",
    "import os\n",
    "\n",
    "# Create .streamlit directory if it doesn't exist\n",
    "os.makedirs(\".streamlit\", exist_ok=True)\n",
    "\n",
    "# Define the theme configuration\n",
    "theme_config = \"\"\"\n",
    "\n",
    "[theme]\n",
    "backgroundColor=\"#eff0f3\"\n",
    "secondaryBackgroundColor=\"#f38f20\"\n",
    "textColor=\"#0c0c0c\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Save the theme configuration to config.toml\n",
    "with open(\".streamlit/config.toml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(theme_config)\n",
    "\n",
    "print(\"Theme configuration saved to .streamlit/config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895440c-d1d7-4c60-b4aa-98b5fc6388eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit run explainable_AI_app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
